{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38a1c414-9f26-4b61-b772-eec27a30c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(os.getcwd()).parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f9301e8-b23b-48f8-a4e9-d223ac854f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (13, 5)\n",
    "\n",
    "seed = 678\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b61aa14-7869-4258-8e9e-1ff1355f0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import lightning as L\n",
    "\n",
    "\n",
    "train_indices = [\n",
    "    21, 54, 103, 67, 109, 10, 338, 297, 332, 284, 251,  # forehead\n",
    "    108, 151, 337,  # forehead lower\n",
    "    143, 156, 70, 63, 105, 66, 107,  # brow right outer\n",
    "    336, 296, 334, 293, 300, 383, 372,  # brow left outer\n",
    "    124, 46, 53, 52, 65, 55, 193,  # brow right middle\n",
    "    285, 295, 282, 283, 276, 353, 417,  # brow left middle\n",
    "    226, 247, 246, 221,  # around right eye\n",
    "    446, 467, 466, 441,  # around left eye\n",
    "    189, 190, 173, 133, 243, 244, 245, 233,  # right z\n",
    "    413, 414, 398, 362, 463, 464, 465, 153,  # left z\n",
    "    58, 172, 136, 150,  # right cheek\n",
    "    288, 397, 365, 379,  # left cheek\n",
    "    468, 469, 470, 471, 472,  # right iris\n",
    "    473, 474, 475, 476, 477,  # left iris\n",
    "]\n",
    "\n",
    "\n",
    "class GazePredictor(L.LightningModule):\n",
    "    def __init__(self, arch):\n",
    "        super().__init__()\n",
    "        self.scaler = StandardScaler()\n",
    "        self.learning_rate = 0.001\n",
    "        self.arch = arch\n",
    "        self.fc1 = nn.Linear(*arch[0:1+1])\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        if len(arch) > 3:\n",
    "            self.hidden1 = nn.Linear(*arch[1:2+1])\n",
    "            self.relu2 = nn.LeakyReLU()\n",
    "        if len(arch) > 4:\n",
    "            self.hidden2 = nn.Linear(*arch[2:3+1])\n",
    "            self.relu3 = nn.LeakyReLU()\n",
    "        if len(arch) > 5:\n",
    "            self.hidden3 = nn.Linear(*arch[3:4+1])\n",
    "            self.relu4 = nn.LeakyReLU()\n",
    "        self.fc2 = nn.Linear(*arch[-2:])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        if len(self.arch) > 3:\n",
    "            x = self.hidden1(x)\n",
    "            x = self.relu2(x)\n",
    "        if len(self.arch) > 4:\n",
    "            x = self.hidden2(x)\n",
    "            x = self.relu3(x)\n",
    "        if len(self.arch) > 5:\n",
    "            x = self.hidden3(x)\n",
    "            x = self.relu4(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), self.learning_rate)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_i, label_i = batch\n",
    "        output_i = self.forward(input_i)\n",
    "        loss = torch.mean((output_i - label_i) ** 2)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_i, label_i = batch\n",
    "        output_i = self.forward(input_i)\n",
    "        loss = torch.mean((output_i - label_i) ** 2)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a644a2-ea7a-41f1-adf1-00ee9735968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train torch.Size([458936, 168]) torch.Size([458936, 2]) mean xy [ 0.01054647 -0.09292439]\n",
      "test  torch.Size([114734, 168]) torch.Size([114734, 2])\n",
      "[168, 256, 64, 2]\n"
     ]
    }
   ],
   "source": [
    "X, y = pickle.load(open('../data/big-dataset.pickle', 'rb'))\n",
    "X = X.reshape(len(X), -1, 2)[:,train_indices].reshape(len(X), len(train_indices) * 2) # each landmark has 2 coordinates (x and y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "input_size = X.shape[1]\n",
    "output_size = y.shape[1]\n",
    "model = GazePredictor([input_size, 256, 64, output_size])\n",
    "model.scaler.fit(X_train)\n",
    "\n",
    "X_train = model.scaler.transform(X_train)\n",
    "X_test = model.scaler.transform(X_test)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_dataloader = DataLoader(train_dataset)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_dataloader = DataLoader(test_dataset)\n",
    "\n",
    "print('train', X_train_tensor.size(), y_train_tensor.size(), 'mean xy', y.mean(axis=0))\n",
    "print('test ', X_test_tensor.size(), y_test_tensor.size())\n",
    "print(model.arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ace43f5b-1f41-4de7-aa4b-d1bf8c8f71a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type      | Params\n",
      "--------------------------------------\n",
      "0 | fc1     | Linear    | 43.3 K\n",
      "1 | relu    | LeakyReLU | 0     \n",
      "2 | hidden1 | Linear    | 16.4 K\n",
      "3 | relu2   | LeakyReLU | 0     \n",
      "4 | fc2     | Linear    | 130   \n",
      "--------------------------------------\n",
      "59.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "59.8 K    Total params\n",
      "0.239     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anatoly/.local/share/virtualenvs/ml-NfG4IkYR/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/anatoly/.local/share/virtualenvs/ml-NfG4IkYR/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1971e4ad264dc28fc873f0f4f9784e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anatoly/.local/share/virtualenvs/ml-NfG4IkYR/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=int(1e3), accelerator='auto', devices='auto')\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
